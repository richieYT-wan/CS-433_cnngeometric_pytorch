{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import h5py as h5\n",
    "import torch\n",
    "import cv2\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing some directory and OS stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richi\\Documents\\EPFL\\Master\\MA3_2\\Machine Learning\\practicals\\projects\\_project2\\LOCAL_code\\testfolder\n"
     ]
    }
   ],
   "source": [
    "# maybe very useful later for a script if we want to create a directory to save data \n",
    "import os\n",
    "x = %pwd\n",
    "path = 'testfolder'\n",
    "test = os.path.join(x,path)\n",
    "print(test)\n",
    "os.mkdir(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richi\\Documents\\EPFL\\Master\\MA3_2\\Machine Learning\\practicals\\projects\\_project2\\LOCAL_code\\../testfolder\n"
     ]
    }
   ],
   "source": [
    "test2 = os.path.join(os.getcwd(),'../testfolder')\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richi\\Documents\\EPFL\\Master\\MA3_2\\Machine Learning\\practicals\\projects\\_project2\n"
     ]
    }
   ],
   "source": [
    "os.chdir('..')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting all frames\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# Opens the Video file\n",
    "# Get your relative filepath for the video, should be something like \".../.../20200624_142043_crop_0_2_4.avi\"\n",
    "cap= cv2.VideoCapture(filepath)\n",
    "outpath = '../misc/video/video_frames/frame_'\n",
    "i=0\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    cv2.imwrite(outpath+str(i)+'.jpg',frame)\n",
    "    i+=1\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying the Model \n",
    "(trained on Car images .... lol)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from model.cnn_geometric_model import CNNGeometric\n",
    "from data.pf_dataset import PFDataset\n",
    "from data.download_datasets import download_PF_willow\n",
    "from image.normalization import NormalizeImageDict, normalize_image\n",
    "from util.torch_util import BatchTensorToVars, str_to_bool\n",
    "from geotnf.transformation import GeometricTnf\n",
    "from geotnf.point_tnf import *\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import warnings\n",
    "from torchvision.transforms import Normalize\n",
    "from collections import OrderedDict\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Can be 'vgg' or 'resnet101'\n",
    "model_aff_path = 'trained_models/base/aff-pascal-vgg/best_aff-pascal-vgg_affine_grid_lossvgg.pth.tar'\n",
    "model_tps_path = 'trained_models/base/bestResnet101/best_checkpoint_adam_tps_grid_lossresnet101.pth.tar'\n",
    "model_hom_path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating CNN model...\n",
      "Loading trained model weights...\n",
      "aff done\n",
      "tps done\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "do_aff = not model_aff_path==''\n",
    "do_tps = not model_tps_path==''\n",
    "do_hom = not model_hom_path==''\n",
    "\n",
    "# Create model\n",
    "print('Creating CNN model...')\n",
    "\n",
    "# CREATING MO\n",
    "if do_aff:\n",
    "    model_aff = CNNGeometric(output_dim=6,use_cuda=use_cuda,\n",
    "                             feature_extraction_cnn='vgg')\n",
    "if do_tps:\n",
    "    model_tps = CNNGeometric(output_dim=18,use_cuda=use_cuda,\n",
    "                             feature_extraction_cnn='resnet101')\n",
    "#if do_hom:\n",
    "#    if four_points:\n",
    "#        model_hom = CNNGeometric(output_dim=8, use_cuda=use_cuda,\n",
    "#                                feature_extraction_cnn=feature_extraction_cnn)\n",
    "#    else : \n",
    "#        model_hom = CNNGeometric(output_dim=9, use_cuda=use_cuda,\n",
    "#                        feature_extraction_cnn=feature_extraction_cnn)\n",
    "# Load trained weights, not much to understand here, it's just that this is how it works.\n",
    "print('Loading trained model weights...')\n",
    "if do_aff:\n",
    "    checkpoint = torch.load(model_aff_path, map_location=lambda storage, loc: storage)\n",
    "    checkpoint['state_dict'] = OrderedDict([(k.replace('vgg', 'model'), v) for k, v in checkpoint['state_dict'].items()])\n",
    "    model_aff.load_state_dict(checkpoint['state_dict'])\n",
    "    print('aff done')\n",
    "if do_tps:\n",
    "    checkpoint = torch.load(model_tps_path, map_location=lambda storage, loc: storage)\n",
    "    checkpoint['state_dict'] = OrderedDict([(k.replace('resnet', 'model'), v) for k, v in checkpoint['state_dict'].items()])\n",
    "    model_tps.load_state_dict(checkpoint['state_dict'])\n",
    "    print('tps done')\n",
    "\n",
    "#Once again, while I wrote these lines, there is no model_homo_path trained so this is just for modularity\n",
    "#if do_hom:\n",
    "#    checkpoint = torch.load(model_hom_path, map_location=lambda storage, loc: storage)\n",
    "#    checkpoint['state_dict'] = OrderedDict([(k.replace('vgg', 'model'), v) for k, v in checkpoint['state_dict'].items()])\n",
    "#    model_hom.load_state_dict(checkpoint['state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpsTnf = GeometricTnf(geometric_model='tps', use_cuda=use_cuda)\n",
    "affTnf = GeometricTnf(geometric_model='affine', use_cuda=use_cuda)\n",
    "homTnf = GeometricTnf(geometric_model='hom', use_cuda=use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here resizes to 240x240 with bi-linear sampling\n",
    "resizeCNN = GeometricTnf(out_h=240, out_w=240, use_cuda = False) \n",
    "\n",
    "def alt_preprocess_image(image,means,stds):\n",
    "    \"\"\"\n",
    "    CALLED alt_preprocess_image because it differs a little bit from the one provided in the demo notebook\n",
    "    \"\"\"\n",
    "    # convert to torch Variable\n",
    "    image = np.expand_dims(image.transpose((2,0,1)),0)\n",
    "    image = torch.Tensor(image.astype(np.float32)/255.0)\n",
    "    image_var = Variable(image,requires_grad=False)\n",
    "    # Resize image using bilinear sampling with identity affine tnf\n",
    "    image_var = resizeCNN(image_var)\n",
    "    # Normalize image\n",
    "    image_var = normalize_image(image_var,mean=means,std=stds)\n",
    "    return image_var\n",
    "\n",
    "means=[0.485, 0.456, 0.406]\n",
    "stds=[0.229, 0.224, 0.225]\n",
    "normalizeTnf = Normalize(mean = means, std=stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_warped(source,target,name):\n",
    "    #Redundant, reloads the image\n",
    "    source_image = io.imread(source)\n",
    "    target_image = io.imread(target)\n",
    "\n",
    "    means=[0.485, 0.456, 0.406]\n",
    "    stds=[0.229, 0.224, 0.225]\n",
    "    #Use the preprocess method declared above to resize, normalize using the means and std computed above\n",
    "    source_image_var = alt_preprocess_image(source_image,means=means, stds=stds)\n",
    "    target_image_var = alt_preprocess_image(target_image,means=means, stds=stds)\n",
    "    \n",
    "    if use_cuda:\n",
    "        source_image_var = source_image_var.cuda()\n",
    "        target_image_var = target_image_var.cuda()\n",
    "    #Create a \"batch\" (i.e. a pair) for the next cell below\n",
    "    batch = {'source_image': source_image_var, 'target_image':target_image_var}\n",
    "    #Resize target: create a function that will resize a given input into the target_image's dimension\n",
    "    resizeTgt = GeometricTnf(out_h=target_image.shape[0], out_w=target_image.shape[1], use_cuda = use_cuda) \n",
    "    #Set the models to eval mode\n",
    "    if do_aff:\n",
    "        model_aff.eval()\n",
    "    if do_tps:\n",
    "        model_tps.eval()\n",
    "    if do_hom:\n",
    "        model_hom.eval()\n",
    "        \n",
    "    # Evaluate models and get the thetas\n",
    "    if do_aff:\n",
    "        theta_aff=model_aff(batch)\n",
    "        warped_image_aff = affTnf(batch['source_image'],theta_aff.view(-1,2,3))\n",
    "    \n",
    "    if do_tps:\n",
    "        theta_tps=model_tps(batch)\n",
    "        warped_image_tps = tpsTnf(batch['source_image'],theta_tps)\n",
    "    \n",
    "    if do_aff and do_tps:\n",
    "        theta_aff_tps=model_tps({'source_image': warped_image_aff, 'target_image': batch['target_image']})        \n",
    "        warped_image_aff_tps = tpsTnf(warped_image_aff,theta_aff_tps)\n",
    "    if do_aff:\n",
    "        warped_image_aff_np = normalize_image(resizeTgt(warped_image_aff),forward=False).data.squeeze(0).transpose(0,1).transpose(1,2).cpu().numpy()\n",
    "    \n",
    "    if do_tps:\n",
    "        warped_image_tps_np = normalize_image(resizeTgt(warped_image_tps),forward=False).data.squeeze(0).transpose(0,1).transpose(1,2).cpu().numpy()\n",
    "    \n",
    "    if do_aff and do_tps:\n",
    "        warped_image_aff_tps_np = normalize_image(resizeTgt(warped_image_aff_tps),forward=False).data.squeeze(0).transpose(0,1).transpose(1,2).cpu().numpy()\n",
    "    x = np.clip(warped_image_aff_tps_np,0,1)\n",
    "    plt.imsave(name, x)\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '../misc/video/'\n",
    "framespath = PATH+'video_frames/frame_'\n",
    "#outputpath = PATH+'iteration_0/'\n",
    "target = framespath+'1117.jpg'\n",
    "outpath = PATH+'aligned_to_1117/from_frame_'\n",
    "for i in range(1715):\n",
    "    source = framespath+str(num)+'.jpg'\n",
    "    outname = outpath+str(num_1)+'to_frame_1117.jpg'\n",
    "    save_warped(source,target,outname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../misc/video/aligned_to_1117/from_frame_\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "print(outpath)\n",
    "img_array = []\n",
    "for i in range(1715):\n",
    "    filename = outpath+str(i)+'to_frame_1117.jpg'\n",
    "    #print(filename)\n",
    "    img = cv2.imread(filename)\n",
    "    height, width, layers = img.shape\n",
    "    size = (width,height)\n",
    "    img_array.append(img)\n",
    "\n",
    "img = cv2.imread(outpath+'0to_frame_1117.jpg')\n",
    "h,w,l = img.shape\n",
    "size = (w,h)\n",
    "out = cv2.VideoWriter('test.mp4',cv2.VideoWriter_fourcc(*'DIVX'), 25, size)\n",
    " \n",
    "for i in range(len(img_array)):\n",
    "    out.write(img_array[i])\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
